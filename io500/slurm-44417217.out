SLURM_JOB_ID: 44417217
dimensions: {"nodes": 10, "ntasks_per_node": 16, "filesystem": {"name": "quobyte", "mountpoint": "/gws/nopw/j04/perf_testing3/stackhpc"}, "stonewall": 300, "iters": 0, "time": "4:0:0", "git_describe": "heads/main-0-g1f83e4c-dirty", "ior_api": "POSIX"}
SLURM_JOB_NODELIST: host[823-832]
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
INFO:    Using cached SIF image
[host830.jc.rl.ac.uk:123811] OPAL ERROR: Unreachable in file ext2x_client.c at line 112
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
***    and potentially your MPI job)
[host830.jc.rl.ac.uk:123811] Local abort before MPI_INIT completed completed successfully, but am not able to aggregate error messages, and not able to guarantee that all other processes were killed!
--------------------------------------------------------------------------
Primary job  terminated normally, but 1 process returned
a non-zero exit code. Per user-direction, the job has been aborted.
--------------------------------------------------------------------------
[host830.jc.rl.ac.uk:123840] OPAL ERROR: Unreachable in file ext2x_client.c at line 112
*** An error occurred in MPI_Init
*** on a NULL communicator
*** MPI_ERRORS_ARE_FATAL (processes in this communicator will now abort,
***    and potentially your MPI job)
[host830.jc.rl.ac.uk:123840] Local abort before MPI_INIT completed completed successfully, but am not able to aggregate error messages, and not able to guarantee that all other processes were killed!
--------------------------------------------------------------------------
mpirun detected that one or more processes exited with non-zero status, thus causing
the job to be terminated. The first process to do so was:

  Process name: [[55971,1],117]
  Exit code:    1
--------------------------------------------------------------------------
[host823:19608] *** Process received signal ***
[host823:19608] Signal: Segmentation fault (11)
[host823:19608] Signal code: Address not mapped (1)
[host823:19608] Failing at address: 0x30
[host823:19608] [ 0] /lib64/libpthread.so.0(+0xf630)[0x7ff66f4a3630]
[host823:19608] [ 1] /apps/eb/software/OpenMPI/4.0.0-GCC-8.2.0-2.31.1/lib/openmpi/mca_pmix_pmix3x.so(OPAL_MCA_PMIX3X_PMIx_server_finalize+0x2bf)[0x7ff66efaea5f]
[host823:19608] [ 2] /apps/eb/software/OpenMPI/4.0.0-GCC-8.2.0-2.31.1/lib/openmpi/mca_pmix_pmix3x.so(pmix3x_server_finalize+0x258)[0x7ff66ef66898]
[host823:19608] [ 3] /apps/sw/eb/software/OpenMPI/4.0.0-GCC-8.2.0-2.31.1/lib/libopen-rte.so.40(pmix_server_finalize+0xa0)[0x7ff67050c2a0]
[host823:19608] [ 4] /apps/eb/software/OpenMPI/4.0.0-GCC-8.2.0-2.31.1/lib/openmpi/mca_ess_hnp.so(+0x3fc0)[0x7ff66f0b8fc0]
[host823:19608] [ 5] /apps/sw/eb/software/OpenMPI/4.0.0-GCC-8.2.0-2.31.1/lib/libopen-rte.so.40(orte_finalize+0x5d)[0x7ff6704e4d9d]
[host823:19608] [ 6] mpirun[0x401201]
[host823:19608] [ 7] /lib64/libc.so.6(__libc_start_main+0xf5)[0x7ff66f0e8555]
[host823:19608] [ 8] mpirun[0x40101e]
[host823:19608] *** End of error message ***
/var/spool/slurmd/job44417217/slurm_script: line 23: 19608 Segmentation fault      mpirun singularity exec --bind /gws/nopw/j04/perf_testing3/stackhpc:/gws/nopw/j04/perf_testing3/stackhpc docker://ghcr.io/stackhpc/io500-singularity:${IO500_CONTAINER_TAG} /io500 /home/users/steveb/io500-lotus/io500/runs/quobyte-10-16-300-0-POSIX/config.quobyte-10-16-300-0-POSIX.ini --timestamp $timestamp
